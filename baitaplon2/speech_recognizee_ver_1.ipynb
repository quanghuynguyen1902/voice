{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "import hmmlearn.hmm\n",
    "import noisereduce as nr\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def noise_cancel(filename, classs, dirr):\n",
    "#     data, fs = librosa.load(os.path.join(dirr,filename))\n",
    "#     reduced_noise = nr.reduce_noise(audio_clip=data, noise_clip=data)\n",
    "#     sf.write('./normal_word/' + classs + '/' + filename, data=reduced_noise, samplerate=fs)\n",
    "# def normal_data():\n",
    "#     class_names = [\"nguoi\", \"toi\", \"khong\", \"mot\" , \"test_khong\", \"benh_nhan\" , \"test_toi\" , \"test_mot\", \"test_nguoi\", \"test_benh_nhan\" ]\n",
    "#     for cname in class_names:\n",
    "#         files = os.listdir(os.path.join(\"word\", cname))\n",
    "#         dirfile = os.path.join(\"word\", cname)\n",
    "#         for f in files:\n",
    "#             if f.endswith(\".wav\"):\n",
    "#                 noise_cancel(f, cname, dirfile)\n",
    "# normal_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_mfcc(file_path):\n",
    "    y, sr = librosa.load(file_path) # read .wav file\n",
    "    hop_length = math.floor(sr*0.010) # 10ms hop\n",
    "    win_length = math.floor(sr*0.025) # 25ms frame\n",
    "    # mfcc is 12 x T matrix\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y, sr, n_mfcc=12, n_fft=1024,\n",
    "        hop_length=hop_length, win_length=win_length)\n",
    "    # substract mean from mfcc --> normalize mfcc\n",
    "    mfcc = mfcc - np.mean(mfcc, axis=1).reshape((-1,1)) \n",
    "    # delta feature 1st order and 2nd order\n",
    "    delta1 = librosa.feature.delta(mfcc, order=1)\n",
    "    delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "    # X is 36 x T\n",
    "    X = np.concatenate([mfcc, delta1, delta2], axis=0) # O^r\n",
    "    # return T x 36 (transpose of X)\n",
    "    return X.T # hmmlearn use T x N matrix\n",
    "\n",
    "def get_class_data(data_dir):\n",
    "    files = os.listdir(data_dir)\n",
    "    mfcc = [get_mfcc(os.path.join(data_dir,f)) for f in files if f.endswith(\".wav\")]\n",
    "    print('data_dir: ', data_dir)\n",
    "    print(f'mfcc.shape: {np.array(mfcc).shape}')\n",
    "    return mfcc\n",
    "\n",
    "def clustering(X, n_clusters=20):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=100, random_state=0, verbose=0)\n",
    "    kmeans.fit(X)\n",
    "    print(\"centers\", kmeans.cluster_centers_.shape)\n",
    "    return kmeans  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load nguoi dataset\n",
      "data_dir:  normal_word/nguoi\n",
      "mfcc.shape: (76,)\n",
      "Load toi dataset\n",
      "data_dir:  normal_word/toi\n",
      "mfcc.shape: (76,)\n",
      "Load khong dataset\n",
      "data_dir:  normal_word/khong\n",
      "mfcc.shape: (76,)\n",
      "Load mot dataset\n",
      "data_dir:  normal_word/mot\n",
      "mfcc.shape: (76,)\n",
      "Load benh_nhan dataset\n",
      "data_dir:  normal_word/benh_nhan\n",
      "mfcc.shape: (75,)\n",
      "Load test_khong dataset\n",
      "data_dir:  normal_word/test_khong\n",
      "mfcc.shape: (25,)\n",
      "Load test_toi dataset\n",
      "data_dir:  normal_word/test_toi\n",
      "mfcc.shape: (25,)\n",
      "Load test_mot dataset\n",
      "data_dir:  normal_word/test_mot\n",
      "mfcc.shape: (25,)\n",
      "Load test_nguoi dataset\n",
      "data_dir:  normal_word/test_nguoi\n",
      "mfcc.shape: (25,)\n",
      "Load test_benh_nhan dataset\n",
      "data_dir:  normal_word/test_benh_nhan\n",
      "mfcc.shape: (25,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class_names = [\"nguoi\", \"toi\", \"khong\", \"mot\", \"benh_nhan\" , \"test_khong\" , \"test_toi\" , \"test_mot\", \"test_nguoi\", \"test_benh_nhan\" ]\n",
    "dataset = {}\n",
    "for cname in class_names:\n",
    "    print(f\"Load {cname} dataset\")\n",
    "    dataset[cname] = get_class_data(os.path.join(\"normal_word\", cname))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get all vectors in the datasets\n",
    "# all_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in dataset.items()], axis=0)\n",
    "# print(\"vectors\", all_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run K-Means algorithm to get clusters\n",
    "# kmeans = clustering(all_vectors)\n",
    "# pickle.dump(kmeans, open('./model/kmean.pk','wb'))\n",
    "# print(\"centers\", kmeans.cluster_centers_.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nguoi \n",
      " (76,)\n",
      "toi \n",
      " (76,)\n",
      "khong \n",
      " (76,)\n",
      "mot \n",
      " (76,)\n",
      "benh_nhan \n",
      " (75,)\n",
      "test_khong \n",
      " (25,)\n",
      "test_toi \n",
      " (25,)\n",
      "test_mot \n",
      " (25,)\n",
      "test_nguoi \n",
      " (25,)\n",
      "test_benh_nhan \n",
      " (25,)\n"
     ]
    }
   ],
   "source": [
    "for key, val in dataset.items():\n",
    "    print(key,'\\n', np.array(val).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "dataset_kmean = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class nguoi\n",
      "(1875, 36) [16, 17, 17, 28, 27, 22, 23, 20, 21, 25, 12, 13, 26, 22, 44, 22, 17, 14, 21, 22, 27, 30, 22, 20, 21, 18, 29, 37, 14, 23, 23, 19, 23, 18, 37, 15, 24, 23, 17, 31, 35, 40, 20, 30, 40, 20, 44, 28, 19, 27, 22, 19, 16, 23, 25, 20, 42, 19, 23, 29, 30, 21, 19, 28, 31, 21, 19, 27, 28, 22, 20, 33, 31, 30, 24, 50] 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -201478.4377             +nan\n",
      "         2     -189238.6448      +12239.7929\n",
      "         3     -187173.7169       +2064.9279\n",
      "         4     -186489.8144        +683.9025\n",
      "         5     -186062.2323        +427.5821\n",
      "         6     -185805.7844        +256.4479\n",
      "         7     -185627.3228        +178.4616\n",
      "         8     -185554.8267         +72.4961\n",
      "         9     -185515.8658         +38.9609\n",
      "        10     -185480.3062         +35.5596\n",
      "        11     -185408.0622         +72.2441\n",
      "        12     -185317.4772         +90.5850\n",
      "        13     -185227.0826         +90.3945\n",
      "        14     -185197.9124         +29.1702\n",
      "        15     -185189.8906          +8.0218\n",
      "        16     -185128.0267         +61.8639\n",
      "        17     -185081.0501         +46.9766\n",
      "        18     -185050.4034         +30.6467\n",
      "        19     -185014.2379         +36.1655\n",
      "        20     -184998.5039         +15.7340\n",
      "        21     -184994.4710          +4.0329\n",
      "        22     -184986.2132          +8.2578\n",
      "        23     -184971.6284         +14.5848\n",
      "        24     -184935.5612         +36.0672\n",
      "        25     -184920.9783         +14.5829\n",
      "        26     -184915.8582          +5.1202\n",
      "        27     -184912.8819          +2.9763\n",
      "        28     -184911.2205          +1.6614\n",
      "        29     -184908.7440          +2.4765\n",
      "        30     -184906.9407          +1.8033\n",
      "        31     -184906.1298          +0.8109\n",
      "        32     -184904.3935          +1.7364\n",
      "        33     -184895.6755          +8.7180\n",
      "        34     -184886.3208          +9.3547\n",
      "        35     -184883.7421          +2.5786\n",
      "        36     -184875.5982          +8.1439\n",
      "        37     -184804.0735         +71.5247\n",
      "        38     -184788.2517         +15.8218\n",
      "        39     -184786.3975          +1.8542\n",
      "        40     -184785.3186          +1.0790\n",
      "        41     -184784.6643          +0.6543\n",
      "        42     -184784.3436          +0.3207\n",
      "        43     -184784.1618          +0.1818\n",
      "        44     -184784.0234          +0.1383\n",
      "        45     -184783.8807          +0.1428\n",
      "        46     -184783.6992          +0.1815\n",
      "        47     -184783.4402          +0.2590\n",
      "        48     -184783.0776          +0.3626\n",
      "        49     -184782.2847          +0.7929\n",
      "        50     -184779.8891          +2.3956\n",
      "        51     -184775.6280          +4.2611\n",
      "        52     -184773.2802          +2.3478\n",
      "        53     -184770.9912          +2.2889\n",
      "        54     -184769.2165          +1.7747\n",
      "        55     -184766.6659          +2.5507\n",
      "        56     -184760.5824          +6.0835\n",
      "        57     -184748.9413         +11.6411\n",
      "        58     -184738.4278         +10.5135\n",
      "        59     -184735.5491          +2.8787\n",
      "        60     -184727.1273          +8.4217\n",
      "        61     -184721.7924          +5.3349\n",
      "        62     -184719.2095          +2.5830\n",
      "        63     -184719.0520          +0.1575\n",
      "        64     -184718.9602          +0.0917\n",
      "        65     -184718.9082          +0.0520\n",
      "        66     -184718.8804          +0.0278\n",
      "        67     -184718.8640          +0.0164\n",
      "        68     -184718.8533          +0.0107\n",
      "        69     -184718.8460          +0.0073\n"
     ]
    }
   ],
   "source": [
    "cname = 'nguoi'\n",
    "# convert all vectors to the cluster index\n",
    "# dataset['one'] = [O^1, ... O^R] , O^r: the r-th recorded wav file \n",
    "# O^r = (c1, c2, ... ct, ... cT) , c_i: the i-th frame in the r-th observation ( or the r-th wav file )\n",
    "# O^r size T x 1\n",
    "# dataset_kmean[cname] = list([kmeans.predict(v).reshape(-1,1) for v in dataset[cname]])\n",
    "\n",
    "\n",
    "hmm = hmmlearn.hmm.GMMHMM(\n",
    "            n_components=9, \n",
    "            n_mix = 4, random_state=10, n_iter=500, verbose=True,\n",
    "            params='mctw', init_params='mct',\n",
    "        )\n",
    "hmm.startprob_prior=np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "hmm.transmat_prior=np.array([\n",
    "    [0.7, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.7, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.7, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.7, 0.3, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.7, 0.3, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.3, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.3, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.3],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "if cname[:4] != 'test':\n",
    "    X = np.concatenate(dataset[cname])\n",
    "    lengths = list([len(x) for x in dataset[cname]])\n",
    "    print(\"training class\", cname)\n",
    "    print(X.shape, lengths, len(lengths))\n",
    "    hmm.fit(X)\n",
    "    models[cname] = hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class toi\n",
      "(1736, 36) [17, 16, 18, 24, 10, 21, 14, 17, 28, 25, 16, 16, 25, 33, 15, 24, 37, 12, 27, 23, 27, 17, 16, 35, 20, 15, 14, 38, 32, 37, 33, 43, 34, 17, 29, 19, 20, 20, 17, 23, 15, 22, 17, 15, 42, 33, 27, 27, 26, 32, 14, 18, 32, 16, 14, 15, 30, 18, 23, 41, 13, 16, 17, 20, 14, 12, 47, 25, 21, 27, 15, 24, 14, 39, 13, 18] 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -185143.3738             +nan\n",
      "         2     -172950.0340      +12193.3398\n",
      "         3     -170370.3253       +2579.7087\n",
      "         4     -169504.0803        +866.2450\n",
      "         5     -169187.0177        +317.0626\n",
      "         6     -168973.9828        +213.0349\n",
      "         7     -168770.5464        +203.4364\n",
      "         8     -168665.0101        +105.5363\n",
      "         9     -168535.6258        +129.3843\n",
      "        10     -168476.1751         +59.4507\n",
      "        11     -168416.1661         +60.0090\n",
      "        12     -168338.4745         +77.6916\n",
      "        13     -168289.3062         +49.1683\n",
      "        14     -168264.6685         +24.6377\n",
      "        15     -168227.4065         +37.2620\n",
      "        16     -168216.7665         +10.6399\n",
      "        17     -168199.8049         +16.9616\n",
      "        18     -168180.7198         +19.0852\n",
      "        19     -168158.7554         +21.9644\n",
      "        20     -168151.5966          +7.1588\n",
      "        21     -168144.3903          +7.2062\n",
      "        22     -168135.5569          +8.8334\n",
      "        23     -168126.0700          +9.4869\n",
      "        24     -168109.5457         +16.5244\n",
      "        25     -168102.3849          +7.1607\n",
      "        26     -168096.8372          +5.5477\n",
      "        27     -168087.6269          +9.2104\n",
      "        28     -168077.0966         +10.5303\n",
      "        29     -168068.8077          +8.2889\n",
      "        30     -168053.0615         +15.7462\n",
      "        31     -168040.3630         +12.6985\n",
      "        32     -168029.2085         +11.1545\n",
      "        33     -168018.6665         +10.5420\n",
      "        34     -167994.2316         +24.4349\n",
      "        35     -167976.5489         +17.6826\n",
      "        36     -167963.7386         +12.8104\n",
      "        37     -167953.5504         +10.1882\n",
      "        38     -167945.6263          +7.9241\n",
      "        39     -167935.5057         +10.1206\n",
      "        40     -167930.9357          +4.5700\n",
      "        41     -167927.9078          +3.0278\n",
      "        42     -167921.9105          +5.9973\n",
      "        43     -167917.0680          +4.8425\n",
      "        44     -167913.7700          +3.2981\n",
      "        45     -167907.3084          +6.4616\n",
      "        46     -167905.0520          +2.2564\n",
      "        47     -167898.8323          +6.2197\n",
      "        48     -167881.7034         +17.1289\n",
      "        49     -167880.9229          +0.7805\n",
      "        50     -167879.6455          +1.2775\n",
      "        51     -167878.5106          +1.1348\n",
      "        52     -167878.1055          +0.4051\n",
      "        53     -167877.7830          +0.3225\n",
      "        54     -167877.4534          +0.3296\n",
      "        55     -167877.0047          +0.4487\n",
      "        56     -167876.0575          +0.9472\n",
      "        57     -167872.2441          +3.8134\n",
      "        58     -167864.1120          +8.1320\n",
      "        59     -167861.1538          +2.9582\n",
      "        60     -167859.6136          +1.5402\n",
      "        61     -167859.2404          +0.3731\n",
      "        62     -167859.0641          +0.1763\n",
      "        63     -167858.9490          +0.1152\n",
      "        64     -167858.8571          +0.0919\n",
      "        65     -167858.7668          +0.0902\n",
      "        66     -167858.6799          +0.0870\n",
      "        67     -167858.6238          +0.0561\n",
      "        68     -167858.6030          +0.0208\n",
      "        69     -167858.5967          +0.0063\n"
     ]
    }
   ],
   "source": [
    "cname = 'toi'\n",
    "# convert all vectors to the cluster index\n",
    "# dataset['one'] = [O^1, ... O^R] , O^r: the r-th recorded wav file \n",
    "# O^r = (c1, c2, ... ct, ... cT) , c_i: the i-th frame in the r-th observation ( or the r-th wav file )\n",
    "# O^r size T x 1\n",
    "# dataset_kmean[cname] = list([kmeans.predict(v).reshape(-1,1) for v in dataset[cname]])\n",
    "\n",
    "\n",
    "hmm = hmmlearn.hmm.GMMHMM(\n",
    "            n_components=9, \n",
    "            n_mix = 4, random_state=10, n_iter=500, verbose=True,\n",
    "            params='mctw', init_params='mct',\n",
    "        )\n",
    "hmm.startprob_prior=np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "hmm.transmat_prior=np.array([\n",
    "    [0.7, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.7, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.7, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.7, 0.3, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.7, 0.3, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.3, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.3, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.3],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "if cname[:4] != 'test':\n",
    "    X = np.concatenate(dataset[cname])\n",
    "    lengths = list([len(x) for x in dataset[cname]])\n",
    "    print(\"training class\", cname)\n",
    "    print(X.shape, lengths, len(lengths))\n",
    "    hmm.fit(X)\n",
    "    models[cname] = hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.89 0.   0.   0.   0.   0.06 0.01 0.   0.04]\n",
      " [0.   0.73 0.   0.01 0.   0.   0.   0.25 0.  ]\n",
      " [0.   0.01 0.78 0.   0.1  0.1  0.   0.   0.  ]\n",
      " [0.   0.   0.   0.85 0.   0.   0.   0.15 0.  ]\n",
      " [0.04 0.01 0.02 0.   0.82 0.06 0.03 0.   0.02]\n",
      " [0.03 0.   0.   0.01 0.01 0.79 0.06 0.   0.1 ]\n",
      " [0.   0.24 0.   0.01 0.   0.   0.68 0.   0.07]\n",
      " [0.   0.   0.24 0.   0.08 0.03 0.   0.66 0.  ]\n",
      " [0.   0.04 0.   0.02 0.01 0.   0.05 0.11 0.77]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=2, suppress=True)\n",
    "print(models['toi'].transmat_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class khong\n",
      "(1898, 36) [27, 17, 27, 27, 33, 21, 20, 23, 29, 45, 25, 26, 27, 33, 35, 20, 30, 20, 28, 16, 22, 21, 15, 28, 24, 17, 22, 24, 18, 26, 22, 23, 25, 33, 25, 14, 33, 21, 20, 27, 23, 19, 20, 22, 25, 19, 30, 31, 18, 20, 21, 19, 20, 28, 25, 17, 26, 20, 38, 40, 25, 27, 25, 34, 34, 20, 24, 23, 23, 28, 27, 25, 26, 36, 32, 19] 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -207646.5482             +nan\n",
      "         2     -194633.0254      +13013.5228\n",
      "         3     -191892.5687       +2740.4567\n",
      "         4     -149395.5483      +42497.0205\n",
      "         5     -149078.8052        +316.7431\n",
      "         6     -148828.9271        +249.8781\n",
      "         7     -148694.3888        +134.5383\n",
      "         8     -148604.5392         +89.8496\n",
      "         9     -148543.8316         +60.7076\n",
      "        10     -148460.8758         +82.9558\n",
      "        11     -148409.2817         +51.5942\n",
      "        12     -148365.1511         +44.1305\n",
      "        13     -148336.1769         +28.9742\n",
      "        14     -148329.9652          +6.2118\n",
      "        15     -148303.3137         +26.6515\n",
      "        16     -148297.2970          +6.0167\n",
      "        17     -148285.0564         +12.2406\n",
      "        18     -148275.7951          +9.2613\n",
      "        19     -148269.3890          +6.4061\n",
      "        20     -148262.8961          +6.4929\n",
      "        21     -148244.7942         +18.1019\n",
      "        22     -148231.0096         +13.7846\n",
      "        23     -148223.8436          +7.1660\n",
      "        24     -148220.3707          +3.4729\n",
      "        25     -148213.9865          +6.3841\n",
      "        26     -148208.4241          +5.5624\n",
      "        27     -148205.4428          +2.9814\n",
      "        28     -148172.7904         +32.6524\n",
      "        29     -148141.5555         +31.2349\n",
      "        30     -148139.9205          +1.6350\n",
      "        31     -148138.3918          +1.5287\n",
      "        32     -148135.4551          +2.9367\n",
      "        33     -148108.8591         +26.5960\n",
      "        34     -148082.3784         +26.4807\n",
      "        35     -148077.1540          +5.2244\n",
      "        36     -148073.0447          +4.1093\n",
      "        37     -148070.4361          +2.6086\n",
      "        38     -148067.2351          +3.2010\n",
      "        39     -148061.8444          +5.3907\n",
      "        40     -148060.2704          +1.5740\n",
      "        41     -148059.5059          +0.7645\n",
      "        42     -148058.7057          +0.8001\n",
      "        43     -148057.7797          +0.9260\n",
      "        44     -148055.9136          +1.8661\n",
      "        45     -148053.9479          +1.9657\n",
      "        46     -148051.6733          +2.2747\n",
      "        47     -148049.0319          +2.6414\n",
      "        48     -148047.2810          +1.7509\n",
      "        49     -148045.0790          +2.2020\n",
      "        50     -148043.9242          +1.1548\n",
      "        51     -148043.5496          +0.3746\n",
      "        52     -148043.3321          +0.2175\n",
      "        53     -148043.1885          +0.1436\n",
      "        54     -148043.0748          +0.1136\n",
      "        55     -148042.9414          +0.1334\n",
      "        56     -148042.6724          +0.2690\n",
      "        57     -148042.0892          +0.5833\n",
      "        58     -148041.5187          +0.5705\n",
      "        59     -148041.1562          +0.3625\n",
      "        60     -148040.9394          +0.2168\n",
      "        61     -148040.8702          +0.0692\n",
      "        62     -148040.8503          +0.0199\n",
      "        63     -148040.8365          +0.0138\n",
      "        64     -148040.8165          +0.0200\n",
      "        65     -148040.7572          +0.0593\n",
      "        66     -148040.3667          +0.3905\n",
      "        67     -148038.2467          +2.1200\n",
      "        68     -148037.4234          +0.8233\n",
      "        69     -148037.3282          +0.0953\n",
      "        70     -148036.8160          +0.5122\n",
      "        71     -148030.4633          +6.3527\n",
      "        72     -148027.8078          +2.6555\n",
      "        73     -148027.7608          +0.0470\n",
      "        74     -148027.7050          +0.0558\n",
      "        75     -148027.5842          +0.1208\n",
      "        76     -148027.2863          +0.2980\n",
      "        77     -148026.9131          +0.3731\n",
      "        78     -148026.8023          +0.1108\n",
      "        79     -148026.7089          +0.0934\n",
      "        80     -148025.8146          +0.8943\n",
      "        81     -148005.2887         +20.5259\n",
      "        82     -147966.9400         +38.3487\n",
      "        83     -147965.9475          +0.9925\n",
      "        84     -147965.9093          +0.0382\n",
      "        85     -147965.8714          +0.0379\n",
      "        86     -147965.8242          +0.0473\n",
      "        87     -147965.7659          +0.0582\n",
      "        88     -147965.7076          +0.0583\n",
      "        89     -147965.6648          +0.0429\n",
      "        90     -147965.6380          +0.0268\n",
      "        91     -147965.6195          +0.0185\n",
      "        92     -147965.6059          +0.0136\n",
      "        93     -147965.5965          +0.0094\n"
     ]
    }
   ],
   "source": [
    "cname = 'khong'\n",
    "# convert all vectors to the cluster index\n",
    "# dataset['one'] = [O^1, ... O^R] , O^r: the r-th recorded wav file \n",
    "# O^r = (c1, c2, ... ct, ... cT) , c_i: the i-th frame in the r-th observation ( or the r-th wav file )\n",
    "# O^r size T x 1\n",
    "# dataset_kmean[cname] = list([kmeans.predict(v).reshape(-1,1) for v in dataset[cname]])\n",
    "\n",
    "\n",
    "hmm = hmmlearn.hmm.GMMHMM(\n",
    "            n_components=9, \n",
    "            n_mix = 4, random_state=10, n_iter=500, verbose=True,\n",
    "            params='mctw', init_params='mct',\n",
    "        )\n",
    "hmm.startprob_prior=np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "hmm.transmat_prior=np.array([\n",
    "    [0.7, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.7, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.7, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.7, 0.3, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.7, 0.3, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.3, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.3, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.3],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "if cname[:4] != 'test':\n",
    "    X = np.concatenate(dataset[cname])\n",
    "    lengths = list([len(x) for x in dataset[cname]])\n",
    "    print(\"training class\", cname)\n",
    "    print(X.shape, lengths, len(lengths))\n",
    "    hmm.fit(X)\n",
    "    models[cname] = hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class mot\n",
      "(1472, 36) [22, 23, 18, 11, 24, 20, 18, 18, 18, 26, 24, 16, 36, 16, 25, 19, 21, 17, 20, 20, 16, 20, 27, 19, 23, 23, 20, 12, 14, 18, 10, 18, 22, 21, 36, 16, 23, 23, 16, 18, 22, 26, 18, 12, 16, 19, 15, 15, 12, 18, 11, 20, 24, 14, 18, 18, 20, 14, 23, 22, 15, 20, 23, 17, 17, 15, 16, 21, 23, 20, 21, 21, 24, 16, 23, 16] 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -157940.8816             +nan\n",
      "         2     -148182.2363       +9758.6453\n",
      "         3     -144463.2704       +3718.9659\n",
      "         4      -68790.9601      +75672.3103\n",
      "         5      -60405.1009       +8385.8592\n",
      "         6      -60173.7229        +231.3780\n",
      "         7      -60066.1990        +107.5239\n",
      "         8      -59967.3704         +98.8286\n",
      "         9      -59872.8753         +94.4951\n",
      "        10      -59780.5727         +92.3025\n",
      "        11      -59689.6452         +90.9276\n",
      "        12      -59655.8599         +33.7852\n",
      "        13      -59630.8882         +24.9718\n",
      "        14      -59621.4027          +9.4855\n",
      "        15      -59607.7830         +13.6197\n",
      "        16      -59599.0683          +8.7147\n",
      "        17      -59588.2026         +10.8657\n",
      "        18      -59577.8853         +10.3172\n",
      "        19      -59560.5156         +17.3697\n",
      "        20      -59522.3092         +38.2064\n",
      "        21      -59477.7475         +44.5618\n",
      "        22      -59445.2405         +32.5069\n",
      "        23      -59436.2014          +9.0391\n",
      "        24      -59428.8227          +7.3788\n",
      "        25      -59417.6249         +11.1977\n",
      "        26      -59407.8925          +9.7324\n",
      "        27      -59399.5157          +8.3769\n",
      "        28      -59385.9893         +13.5264\n",
      "        29      -59381.5670          +4.4223\n",
      "        30      -59370.9466         +10.6204\n",
      "        31      -59349.8623         +21.0843\n",
      "        32      -59311.7016         +38.1607\n",
      "        33      -59300.6080         +11.0936\n",
      "        34      -59301.8041          -1.1961\n"
     ]
    }
   ],
   "source": [
    "cname = 'mot'\n",
    "# convert all vectors to the cluster index\n",
    "# dataset['one'] = [O^1, ... O^R] , O^r: the r-th recorded wav file \n",
    "# O^r = (c1, c2, ... ct, ... cT) , c_i: the i-th frame in the r-th observation ( or the r-th wav file )\n",
    "# O^r size T x 1\n",
    "# dataset_kmean[cname] = list([kmeans.predict(v).reshape(-1,1) for v in dataset[cname]])\n",
    "\n",
    "\n",
    "hmm = hmmlearn.hmm.GMMHMM(\n",
    "            n_components=9, \n",
    "            n_mix = 4, random_state=10, n_iter=500, verbose=True,\n",
    "            params='mctw', init_params='mct',\n",
    "        )\n",
    "hmm.startprob_prior=np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "hmm.transmat_prior=np.array([\n",
    "    [0.7, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.7, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.7, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.7, 0.3, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.7, 0.3, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.3, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.3, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.3],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "if cname[:4] != 'test':\n",
    "    X = np.concatenate(dataset[cname])\n",
    "    lengths = list([len(x) for x in dataset[cname]])\n",
    "    print(\"training class\", cname)\n",
    "    print(X.shape, lengths, len(lengths))\n",
    "    hmm.fit(X)\n",
    "    models[cname] = hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class benh_nhan\n",
      "(3422, 36) [45, 43, 33, 47, 54, 37, 29, 47, 42, 67, 55, 57, 48, 39, 46, 34, 45, 44, 39, 38, 41, 46, 28, 51, 70, 42, 71, 48, 42, 59, 39, 34, 35, 67, 58, 39, 39, 46, 85, 30, 55, 34, 42, 44, 50, 26, 58, 44, 33, 44, 43, 41, 37, 37, 40, 48, 56, 35, 37, 36, 42, 48, 69, 52, 39, 25, 36, 51, 56, 74, 32, 63, 55, 54, 27] 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -383596.8479             +nan\n",
      "         2     -358896.9886      +24699.8593\n",
      "         3     -351788.1907       +7108.7980\n",
      "         4     -349403.2849       +2384.9058\n",
      "         5     -348617.4875        +785.7974\n",
      "         6     -348196.9741        +420.5134\n",
      "         7     -347796.4782        +400.4959\n",
      "         8     -347414.5592        +381.9190\n",
      "         9     -347191.5819        +222.9773\n",
      "        10     -346940.7880        +250.7939\n",
      "        11     -346838.0236        +102.7644\n",
      "        12     -346770.1094         +67.9141\n",
      "        13     -346691.6250         +78.4844\n",
      "        14     -346641.4180         +50.2070\n",
      "        15     -346527.7857        +113.6323\n",
      "        16     -346455.2738         +72.5120\n",
      "        17     -346341.0557        +114.2180\n",
      "        18     -346150.2372        +190.8185\n",
      "        19     -346040.8864        +109.3508\n",
      "        20     -345963.6874         +77.1991\n",
      "        21     -345911.0311         +52.6563\n",
      "        22     -345862.6165         +48.4146\n",
      "        23     -345837.4946         +25.1219\n",
      "        24     -345825.2147         +12.2800\n",
      "        25     -345809.9927         +15.2220\n",
      "        26     -345791.0155         +18.9772\n",
      "        27     -345759.1735         +31.8419\n",
      "        28     -345732.4538         +26.7197\n",
      "        29     -345720.8513         +11.6025\n",
      "        30     -345700.6310         +20.2203\n",
      "        31     -345691.0330          +9.5980\n",
      "        32     -345683.1254          +7.9076\n",
      "        33     -345673.4321          +9.6933\n",
      "        34     -345660.0578         +13.3744\n",
      "        35     -345645.8390         +14.2187\n",
      "        36     -345629.3158         +16.5233\n",
      "        37     -345611.1293         +18.1865\n",
      "        38     -345604.5561          +6.5732\n",
      "        39     -345599.6595          +4.8965\n",
      "        40     -345590.6341          +9.0255\n",
      "        41     -345570.9741         +19.6599\n",
      "        42     -345560.5102         +10.4639\n",
      "        43     -345553.9943          +6.5159\n",
      "        44     -345536.3286         +17.6657\n",
      "        45     -345515.8807         +20.4479\n",
      "        46     -345503.2108         +12.6699\n",
      "        47     -345485.2817         +17.9291\n",
      "        48     -345471.2057         +14.0760\n",
      "        49     -345458.5115         +12.6942\n",
      "        50     -345446.3485         +12.1631\n",
      "        51     -345430.2693         +16.0791\n",
      "        52     -345416.6356         +13.6338\n",
      "        53     -345400.6404         +15.9952\n",
      "        54     -345385.4946         +15.1458\n",
      "        55     -345349.3874         +36.1072\n",
      "        56     -345318.5440         +30.8433\n",
      "        57     -345308.9930          +9.5510\n",
      "        58     -345303.7169          +5.2761\n",
      "        59     -345298.7686          +4.9483\n",
      "        60     -345289.2933          +9.4753\n",
      "        61     -345282.0337          +7.2596\n",
      "        62     -345277.5268          +4.5068\n",
      "        63     -345268.2440          +9.2828\n",
      "        64     -345252.2193         +16.0247\n",
      "        65     -345245.6634          +6.5560\n",
      "        66     -345242.8327          +2.8307\n",
      "        67     -345238.6117          +4.2211\n",
      "        68     -345234.6889          +3.9228\n",
      "        69     -345230.5647          +4.1241\n",
      "        70     -345225.7180          +4.8467\n",
      "        71     -345222.9270          +2.7910\n",
      "        72     -345221.2063          +1.7207\n",
      "        73     -345220.8545          +0.3518\n",
      "        74     -345221.2040          -0.3495\n"
     ]
    }
   ],
   "source": [
    "cname = 'benh_nhan'\n",
    "\n",
    "\n",
    "hmm = hmmlearn.hmm.GMMHMM(\n",
    "            n_components=18, \n",
    "            n_mix = 4, random_state=10, n_iter=500, verbose=True,\n",
    "            params='mctw', init_params='mct',\n",
    "        )\n",
    "hmm.startprob_prior=np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "hmm.transmat_prior=np.array([ \n",
    "    [0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.3],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
    "    ])\n",
    "\n",
    "\n",
    "if cname[:4] != 'test':\n",
    "    X = np.concatenate(dataset[cname])\n",
    "    lengths = list([len(x) for x in dataset[cname]])\n",
    "    print(\"training class\", cname)\n",
    "    print(X.shape, lengths, len(lengths))\n",
    "    hmm.fit(X)\n",
    "    models[cname] = hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(models, open('./model/models.pk','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[\"test_nguoi\"] = list([kmeans.predict(v).reshape(-1,1) for v in dataset['test_nguoi']])\n",
    "# print(dataset[\"test_nguoi\"])\n",
    "# dataset['test_toi'] = list([kmeans.predict(v).reshape(-1,1) for v in dataset['test_toi']])\n",
    "# dataset['test_khong'] = list([kmeans.predict(v).reshape(-1,1) for v in dataset['test_khong']])\n",
    "# dataset['test_mot'] = list([kmeans.predict(v).reshape(-1,1) for v in dataset['test_mot']])\n",
    "# dataset['test_benh_nhan'] = list([kmeans.predict(v).reshape(-1,1) for v in dataset['test_benh_nhan']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "test_nguoi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 25 / 25\n",
      "test_toi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 25 / 25\n",
      "test_khong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 25 / 25\n",
      "test_mot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 18 / 25\n",
      "test_benh_nhan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 25 / 25\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing\")\n",
    "mapping = [\"nguoi\", \"toi\", \"khong\", \"mot\", \"benh_nhan\"]\n",
    "class_names = [\"test_nguoi\", \"test_toi\", \"test_khong\", \"test_mot\", \"test_benh_nhan\"]\n",
    "\n",
    "for true_cname in class_names:\n",
    "    print(true_cname)\n",
    "    score = []\n",
    "    count = 0\n",
    "    correct = 0\n",
    "    for i in dataset[true_cname]:\n",
    "        score = [model.score(i, [len(i)]) for cname, model in models.items() if cname[:4] != 'test']\n",
    "        res = mapping[score.index(max(score))] \n",
    "        \n",
    "        if res == true_cname[5:]:\n",
    "            correct += 1\n",
    "        count += 1 \n",
    "    print('accuracy {} / {}'.format(correct, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(100*correct/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
